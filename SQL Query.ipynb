{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "430f9709-be6f-4e9a-8eaa-8ab97e3c6b8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Ways to get second highest salary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "764ec79e-c749-449e-8bc5-49ed5c27241b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1.Using max and limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f6a5e4f-e649-4727-b61d-d22b5c4fc1d1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"SecondHighestSalary\").getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = [(1, 5000), (2, 6000), (3, 8000), (4, 8000), (5, 7000)]\n",
    "columns = [\"id\", \"salary\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Register the DataFrame as a SQL temporary view\n",
    "df.createOrReplaceTempView(\"employees\")\n",
    "\n",
    "# SQL query to find second-highest salary\n",
    "query = \"\"\"\n",
    "SELECT Max (salary)\n",
    "FROM employees where salary<(SELECT Max (salary)\n",
    "FROM employees)\n",
    "LIMIT 1\n",
    "\"\"\"\n",
    "\n",
    "# Execute SQL query\n",
    "result = spark.sql(query)\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4976a3a0-6971-4093-b67e-f4d10ebaf942",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "using dense Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "adcc364c-102a-459e-a055-10dee06bc128",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"SecondHighestSalary\").getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = [(1, 5000), (2, 6000), (3, 8000), (4, 8000), (5, 7000)]\n",
    "columns = [\"id\", \"salary\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Register the DataFrame as a SQL temporary view\n",
    "df.createOrReplaceTempView(\"employees\")\n",
    "\n",
    "# SQL query to find second-highest salary\n",
    "query = \"\"\"\n",
    "SELECT salary \n",
    "FROM (\n",
    "    SELECT salary, DENSE_RANK() OVER (ORDER BY salary DESC) as rnk\n",
    "    FROM employees\n",
    ") ranked\n",
    "WHERE rnk = 2\n",
    "\"\"\"\n",
    "\n",
    "# Execute SQL query\n",
    "result = spark.sql(query)\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "746854c1-e194-4a7c-9176-95142a58fcb1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Using Rank ****Key Differences Between RANK() and DENSE_RANK()\n",
    "Function\tHandles Duplicates?\tRank Gaps?\n",
    "RANK()\tYes\tSkips ranks when duplicates exist\n",
    "DENSE_RANK()\tYes\tNo rank gaps\n",
    "For example, if salaries are (8000, 8000, 7000, 6000, 5000):\n",
    "\n",
    "RANK() results: (8000 → rank 1, 8000 → rank 1, 7000 → rank 3, 6000 → rank 4)\n",
    "DENSE_RANK() results: (8000 → rank 1, 8000 → rank 1, 7000 → rank 2, 6000 → rank 3)\n",
    "So, if you want the second-highest salary even when there are duplicates, DENSE_RANK() is safer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e6ae1682-7078-410d-92b9-4201e0458f8e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"SecondHighestSalary\").getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = [(1, 5000), (2, 6000), (3, 8000), (4, 8000), (5, 7000)]\n",
    "columns = [\"id\", \"salary\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Register the DataFrame as a SQL temporary view\n",
    "df.createOrReplaceTempView(\"employees\")\n",
    "\n",
    "# SQL query using RANK() with DISTINCT\n",
    "query = \"\"\"\n",
    "SELECT salary \n",
    "FROM (\n",
    "    SELECT DISTINCT salary, RANK() OVER (ORDER BY salary DESC) as rnk\n",
    "    FROM employees\n",
    ") ranked\n",
    "WHERE rnk = 2\n",
    "\"\"\"\n",
    "\n",
    "# Execute SQL query\n",
    "result = spark.sql(query)\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ddc5a942-d5af-4521-8f7c-29b2d95c8eda",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Using LAG() Window Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f5f920f-75d0-4024-8e9b-aa8876d4b342",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"SecondHighestSalary\").getOrCreate()\n",
    "\n",
    "# Sample data\n",
    "data = [(1, 5000), (2, 6000), (3, 8000), (4, 8000), (5, 7000)]\n",
    "columns = [\"id\", \"salary\"]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Register the DataFrame as a SQL temporary view\n",
    "df.createOrReplaceTempView(\"employees\")\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT max(salary) \n",
    "FROM (\n",
    "    SELECT salary, LAG(salary) OVER (ORDER BY salary DESC) AS prev_salary\n",
    "    FROM (SELECT DISTINCT salary FROM employees)\n",
    ") t\n",
    "WHERE prev_salary IS NOT NULL\n",
    "\"\"\"\n",
    "\n",
    "result = spark.sql(query)\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5971e8d0-7e9e-4f2e-94e4-bd2dafc66339",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Using stored procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "81bc8996-1906-4dc2-9c33-1b2c477fb650",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+\n|salary|\n+------+\n|  7000|\n+------+\n\n"
     ]
    }
   ],
   "source": [
    "# Create sample data\n",
    "data = [(1, 5000), (2, 6000), (3, 8000), (4, 8000), (5, 7000)]\n",
    "columns = [\"id\", \"salary\"]\n",
    "\n",
    "df = spark.createDataFrame(data, columns)\n",
    "\n",
    "# Register the DataFrame as a SQL temporary view\n",
    "df.createOrReplaceTempView(\"employees\")\n",
    "\n",
    "# Create a stored procedure alternative (function)\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW second_highest_salary AS \n",
    "SELECT salary FROM (\n",
    "    SELECT DISTINCT salary, DENSE_RANK() OVER (ORDER BY salary DESC) as rnk\n",
    "    FROM employees\n",
    ") ranked WHERE rnk = 2\n",
    "\"\"\")\n",
    "result = spark.sql(\"SELECT * FROM second_highest_salary\")\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b1626e3c-4a7a-4153-803a-b72ccd146e69",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "SQL Query",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
